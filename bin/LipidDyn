#!/usr/bin/env python

# Copyright (C) 2019, Simone Scrima, Alessia Campo, Matteo Tiberti

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

import time
import errno
import subprocess
import sys
import os
import os.path as path
import argparse
import shutil
from pathlib import Path
import glob
from progressbar import ProgressBar
import numpy as np
import logging
import yaml
import pandas as pd

#Import the classes and functions from the utils
from LipidDyn.core import *
from LipidDyn.utils import *

# Import pkg management library
import pkg_resources

#Import MDanalysis
import MDAnalysis as mda
from MDAnalysis.analysis.leaflet import LeafletFinder

#Import Lipyphilic 
from lipyphilic.lib.order_parameter import SCC


_start_time = time.time()

def tic():
    global _start_time
    _start_time = time.time()


def tac():
    t_sec = round(time.time() - _start_time)
    (t_min, t_sec) = divmod(t_sec,60)
    (t_hour,t_min) = divmod(t_min,60)
    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))
    

def module_fatslim(trajectory_file,
                   topology_file,
                   index_headgroups,
                   out_dir,
                   apl_cutoff,
                   tck_cutoff,
                   raw,
                   species,
                   ncore,
                   RS_convert
                   ):

    """Fuction consisting of fatslim analysis
    1) Thickness (raw +xvg)
    2) APL (raw+xvg)

    Parameters
    ----------
    trajectory_file : str
            Name of the processed .xtc file.
    
    topology_file : str
            Name of the last producte .gro file.
    
    index_headgroups : str
            Filename of the index containing all the headgroups
    
    directory_name : str
            Name of the output folder
    
    apl_cutoff : float
            Number representing the cut-off for the APL
    
    tck_cutoff : float
            Number representing the cut-off for the thickness
    
    raw : True/False
          Value to include or not the raw output
          
    species : True/False
          Value to include lipid species specific output
    
    ncore : int
            Number of cores for parallelization
            
    RS_convert : df
            Dataframe that defines the converson from residue ID to lipid class
    """



    # Output directory
    analysis_fatlism = os.path.abspath(os.path.join(out_dir, 'Fatslim'))
    if not os.path.exists(analysis_fatlism):
        try:
            os.mkdir((analysis_fatlism))
        except OSError as exc:
            if exc.errno != errno.EEXIST:
                raise



    # Begins of the fatslim analysis
    fatslim = FatslimCommands(trajectory_file,
                              topology_file,
                              index_headgroups,
                              ncore,
                              apl_cutoff,
                              tck_cutoff)
    # progress bar
    pbar = ProgressBar().start()
    step = 8
    pbar.update((1/step)*100) # current step/total steps * 100    

    # prepare directories      
    if not os.path.exists(analysis_fatlism + '/raw_data/apl') \
    or not os.path.exists(analysis_fatlism + '/raw_data/thickness') \
    or not os.path.exists(analysis_fatlism + '/average'):
        try: 
            os.mkdir((analysis_fatlism +'/raw_data'))
            os.mkdir((analysis_fatlism +'/raw_data/apl'))
            os.mkdir((analysis_fatlism +'/raw_data/thickness'))
            os.mkdir((analysis_fatlism +'/average'))
        except OSError as exc:
            if exc.errno != errno.EEXIST:
                raise
    
    # create average xvg files
    pbar.update((2/step)*100)
    fatslim.thickness(out_file = analysis_fatlism +'/average/thickness.xvg')
    
    pbar.update((3/step)*100)
    fatslim.AreaPerLipid(out_file = analysis_fatlism + '/average/apl.xvg')

        
    if raw or species:    
        # create raw files
        pbar.update((4/step)*100)
        fatslim.raw_AreaPerLipid(out_file = analysis_fatlism + '/raw_data/apl/raw_apl.csv')
        
        pbar.update((5/step)*100)
        fatslim.raw_thickness(out_file = analysis_fatlism + '/raw_data/thickness/raw_thickness.csv')
    
        if species:   
            if not os.path.exists(analysis_fatlism + '/species'):
                try: 
                    os.mkdir((analysis_fatlism + '/species'))
                except OSError as exc:
                    if exc.errno != errno.EEXIST:
                        raise
                    
            # create single species xvgs
            pbar.update((7/step)*100)
            fatslim.SpeciesXVG(RawDir = analysis_fatlism + '/raw_data/apl',
                               XvgDir = analysis_fatlism + '/average/apl.xvg', 
                               RS_convert = RS_convert,
                               out_file = analysis_fatlism + '/species')
            
            pbar.update((8/step)*100)
            fatslim.SpeciesXVG(RawDir = analysis_fatlism + '/raw_data/thickness',
                               XvgDir = analysis_fatlism + '/average/thickness.xvg',
                               RS_convert = RS_convert,
                               out_file = analysis_fatlism + '/species')    

    if not raw:
        # remove raw files                            
        shutil.rmtree(analysis_fatlism + '/raw_data')
         
    pbar.finish()


def module_densmap(universe,
                   leaflets,
                   ncore,
                   out_dir):

    """
    Parameters
    -------------
    universe : class
        MDAnalysis universe class
    
    leaflets : dict
        Dictionary with MDAnalysis AtomGroup as keys of all
        the lipid residues in upper and lower leaflet.
        Obtained using LeafletFinder class in MDAnalysis
    
    ncore : int
        Number of cores for parallelization
    
    out_dir : str
        Name of the output folder
    """

    # output directory
    folder = os.path.abspath(os.path.join(out_dir,'2D_maps'))
    if not os.path.exists(folder):
        try:
            os.mkdir((folder))
        except OSError as exc: # Guard against race condition
            if exc.errno != errno.EEXIST:
                raise

    # progress bar
    pbar = ProgressBar().start()
    total_step = 2
    step = 1
    dmap = Density(universe,
                   ncore)
    
    for leaflet in leaflets:
        leaflet_atoms = leaflets[leaflet].residues.atoms
        # compute density maps for each leaflet
        grid = dmap.multiprocessing(leaflet_atoms)
        # output file
        np.savetxt(folder+"/"+leaflet+"_2dmap.dat",
                   grid,
                   delimiter='\t',
                   fmt='%1.4f')
        pbar.update((step/total_step)*100) # update status
        step += 1
    pbar.finish()


def module_enrichment(universe,
                      leaflets,
                      dict_selection,
                      ncore,
                      out_dir):
    """
    Parameters
    -------------
    universe : class
        MDAnalysis universe class
    
    leaflets: dict
        MDAnalysis AtomGroup selection of all the
        lipid residue constituting each leaflet
    
    dict_selection: dict
        dictionary from config file to parse the ratio 
        in bulk of each lipid if specified 
    
    ncore : int
        Number of cores for parallelization
    
    out_dir : str
        Name of the output folder
    """

    # output directory
    folder = os.path.abspath(os.path.join(out_dir,'Enrichment'))
    if not os.path.exists(folder):
        try:
            os.mkdir((folder))
        except OSError as exc: # Guard against race condition
            if exc.errno != errno.EEXIST:
                raise

    pbar = ProgressBar().start()
    total_step = 2
    step = 1
    dmap = Density(universe,
                   ncore)
   
    conc={}     # dictionary to store the concentration in bulk of each lipid
    for leaflet in leaflets:
        d = {} # dictionary to store all the arrays for the dmaps
        # get the density of each leaflet and add to dict
        d[leaflet] = dmap.multiprocessing(leaflets[leaflet].residues.atoms)
        
        # get the lipids type names in the leaflet 
        membrane = np.unique(leaflets[leaflet].residues.resnames)
        
        # get the total number of lipids per leaflet 
        tot_lipids = len(leaflets[leaflet].residues) 

        # get and add densities of different lipid types on each leaflet
        for lipid in membrane:
            # select each type of lipid on the leaflet              
            sel = leaflets[leaflet].select_atoms("resname " + lipid)
            # get the densities of each type and add to dict
            d[lipid] = dmap.multiprocessing(sel.residues.atoms)
            
            lipid_num = len(sel.residues)  # get the total number of each lipid type

            # get the ratio from the config file 
            ratio=bool(dict_selection[lipid]['bulk_ratio'])
            
            # if ratio is specified in the config file
            if ratio: 
                conc[lipid]=dict_selection[lipid]['bulk_ratio']
                
            # if ratio is not specified         
            else:
                conc[lipid]= lipid_num / tot_lipids
                
              
        d1 = {}
        for key in d:
            # ignore leaflets densities
            if key == leaflet:
                continue
            # normalize dividing single lipids densities by the leaflet density
            array = np.divide(d[key],
                              d[leaflet],
                              out=np.zeros_like(d[key]),
                              where=d[leaflet]!=0)
            d1[key] = array

        # divide the previous lipid map by the concentration in bulk of the lipid 
        for key in d1:
            
            array = np.divide(d1[key],
                              conc[key], 
                              out=np.zeros_like(d1[key]),
                              where=conc[key]!=0) 

            # substitute the first column and rows with their original values
            array[:,0] = d[key][:,0]
            array[0,:] = d[key][0,:]

            np.savetxt(folder+"/"+key+"_"+leaflet+"_enrich.dat",
                        array,
                        delimiter='\t',
                        fmt='%1.4f')
    
        pbar.update((step/2)*100)

    pbar.finish()



def module_movements(universe,
                     leaflets,
                     out_dir):

    # Creates different folder in which the output is stored

    """From the imported module uses these function to extract the
    trajectories associated with each lipids of both upper and lower
    leaflet

    Parameters
    ----------
    universe : obj
            Universe object from MDAnalysis library
    
    leaflets : dict
        Dictionary with MDAnalysis AtomGroup as keys of all
        the lipid residues in upper and lower leaflet.
        Obtained using LeafletFinder class in MDAnalysis
    
    out_dir : str
            Name of the output folder
    """

    # output directory
    analysis_traj = os.path.abspath(os.path.join(out_dir,  "Diffusion_movements"))
    if not os.path.exists(analysis_traj):
        try:
            os.mkdir((analysis_traj))
        except OSError as exc: # Guard against race condition
            if exc.errno != errno.EEXIST:
                raise

    # progress bar
    pbar = ProgressBar().start()
    total_step = len(leaflets["upper_leaflet"].residues)*2
    step = 1

    leaflet_filenames = {"upper_leaflet" : "Upper_leaflet_coordinates.dat",
                         "lower_leaflet" : "Lower_leaflet_coordinates.dat"}

    # iterate through the dictionary
    for leaflet in leaflets.keys():
        try:
            filename = leaflet_filenames[leaflet]
        except KeyError:
            logging.warning(f"Could not recognize leaflet name: {leaflet}, ignoring")
            continue

        # create outputfile in the directory
        with open(analysis_traj+"/"+filename, "w") as g:
            # iterate through the residues contained in the leaflet
            for residue in leaflets[leaflet].residues:
                g.write("> " + str(residue).strip("<>").replace(",", "") + "\n")
                # for every frame in the trajectory

                for ts in universe.trajectory:
                    # extract x and y coordinate of the center of mass
                    g.write(np.array2string(
                                residue.atoms.center_of_mass()[0:2]/10,\
                                precision=3, separator='\t').strip("[]")+"\n")
                pbar.update((step/total_step)*100)
                step += 1
    pbar.finish()




def module_order_parameter(u,
                           lipid_resnames,
                           trajectory_file,
                           topology_file,
                           parsed_yaml,
                           out_dir
                           ):

    """
    Parameters
    ----------
    u : MDAnalysis Universe object
    
    lipid_resnames : list 
            Contains the lipid residue names

    trajectory_file : str
            Name of the processed .xtc file.
    
    topology_file : str
            Name of the last producte .gro file.
    
    parsed_yaml : dict
            Contains the sn beads definition for
            OP calculation

    out_dir : str
            Name of the output folder
    """

  
    # Creates different folder in which the output is stored

    order_folder = os.path.join(out_dir, 'Order_Parameter')

    if not os.path.exists(order_folder):
        try:
            os.mkdir((order_folder))
        except OSError as exc: # Guard against race condition
            if exc.errno != errno.EEXIST:
                raise
    
    

    # check if the system is CG from the config file    # ADD PBAR()
    if parsed_yaml['forcefield'] == 'CG':
        pbar = ProgressBar().start()
        total_step = len(lipid_resnames)
        step = 1
        # dict to store the op values for each lipid- for each sn
        scc_dict={}
        for lipid in lipid_resnames:
            scc_dict[lipid]={}
            for sn in ['sn1', 'sn2']:
                if sn in parsed_yaml['lipids'][lipid].keys(): # exclude all the lipid with no acyl-chain 
                    if parsed_yaml['lipids'][lipid][sn]: # exclude lipids in which sn is not specified
                        
                        # compute the OP for each lipid- for each sn and store into dict
                        scc_dict[lipid][sn]=get_OP_cg(u,
                                                      parsed_yaml['lipids'][lipid][sn],
                                                      lipid,
                                                      sn)

        # parse the dict and write the output file
        for key, values in scc_dict.items():
            new_dict=scc_dict[key]
            # exclude all the keys without OP value
            if key and values:

                try:
                    with open('Order_Parameter_'+ key +'.csv',"w") as f:

                        f.write("{},{},{},{},{},{},{}\n".format('OP_name','resname','atom1','atom2','OP_mean', 'OP_std', 'OP_stem'))
                        # get the sn chain, the CC-atoms and the op value  
                        for sn, at in new_dict.items():
                            for k, v in at.items():
                                f.write("{},{},{},{},{},{},{}\n".format(sn,key,k[4:6], k[7::], v[0], v[1], v[2]))
                except:
                    logging.warning("Problem writing the main outputfile")


                shutil.move('Order_Parameter_'+ key +'.csv',
                            order_folder)

            pbar.update((step/total_step)*100)
            step+=1
        pbar.finish()

    # check if the system is FA from the config file
    elif parsed_yaml['forcefield'] == 'FA':
        
        # retrieve def file for the op in the package folder
        dirs =  pkg_resources.resource_listdir('LipidDyn','/definitions_files/')

        pbar = ProgressBar().start()
        total_step = len(dirs)
        step = 1
        for def_file in dirs:

            # get the lipid name
            lipid_name = def_file.split('.')[0]
            # retrieve the def files from the package
            defi = pkg_resources.resource_string('LipidDyn','/definitions_files/'+
                                              def_file)
            defi = defi.decode("utf-8").split('\n') # decode the strings from bytes
            defi = list(filter(lambda x: x != '', defi)) # filter empty strings
            ordPars = parse_op_input(defi)
        
            read_trajs_calc_OPs(ordPars,
                                topology_file,
                                [trajectory_file]
                                )

            for op in ordPars.values():
                (op.avg, op.std, op.stem) = op.get_avg_std_stem_OP


            # writes the output file in  file
            try:
                with open('Order_Parameter_'+ lipid_name +'.csv',"w") as f:
                    f.write("{},{},{},{},{},{},{}  \n".format(
                    'OP_name','resname','atom1','atom2','OP_mean','OP_stddev','OP_stem'))
                    for op in ordPars.values():
                        # output in csv file format comma separated
                        f.write(
                            "{},{},{},{},{: 2.5f},{: 2.5f},{: 2.5f} \n".format(
                                op.name, op.resname, op.atAname,
                                op.atBname,op.avg, op.std, op.stem)
                            )
            except:
                logging.warning("Problem writing the main outputfile")


            with open('Order_Parameter_'+ lipid_name +'.csv','r') as g :
                if "nan" in g.read():
                    os.remove('Order_Parameter_'+ lipid_name +'.csv')
                else:
                    shutil.move('Order_Parameter_'+ lipid_name +'.csv',
                                order_folder)

            pbar.update((step/total_step)*100)
            step += 1
        pbar.finish()


def module_curvature(universe,
                     parsed_yaml,
                     out_dir
                     ):
    """
    Parameters
    -------------
    universe : class
        MDAnalysis universe class
        
    parsed_yaml : dict
            Contains the beads definition for
            leaflet curvature calculation    
    
    out_dir : str
        Name of the output folder
    """        

    # define number of bins based on size of universe
    # unless provided in configuration file
    bins = parsed_yaml["bins"] 
    
    if bins == None:
        print(" ")
        print("!!!bins not defined in configuration file; bin size set to 20 Angstrom!!! ")
        bins = round(universe.dimensions[0]/20) 
        print(" ")

    # define dictionary 
    dict_selection = parsed_yaml["lipids"] 

    
    # define headgroups
    g = select_lipid_headgroups(universe, dict_selection)  
    
    # output directory
    out_folder = os.path.abspath(os.path.join(out_dir, "curv"))

    if not os.path.exists(out_folder):
        try:
            os.mkdir((out_folder)) 
        except OSError as exc: # Guard against race condition
            if exc.errno != errno.EEXIST:
                raise 

    # find leaflets and store them in a dictionary
    L = LeafletFinder(universe, g) 
    
    upper_leaflet = L.groups(0)
    lower_leaflet = L.groups(1)
    
    # simplify array to have only one of each headgroup found 
    selection_up = np.unique(upper_leaflet.names)
    selection_low = np.unique(lower_leaflet.names)

    # turn headgroup selections into string
    sentence = list()
    for x in range(len(selection_up) - 1):
        sentence.append(str(selection_up[x]) + " or name")
    sentence.append(str(selection_up[-1]))
    sentence = ' '.join(sentence)
    
    sentence1 = list()
    for x in range(len(selection_low) - 1):
        sentence1.append(str(selection_low[x]) + " or name")
    sentence1.append(str(selection_low[-1]))
    sentence1 = ' '.join(sentence1)
   

    # define upper and lower leaflet headgroups for string
    up_string = (" and (name "
                + sentence
                + ")")

    low_string = (" and (name "
                 + sentence1
                 + ")")


    # define residues for each leaflet
    sel_upper = " ".join([str(r) for r in upper_leaflet.residues.resids])
    sel_lower = " ".join([str(r) for r in lower_leaflet.residues.resids])

    # define full selection string 
    upper_string = "resid {} {}".format(sel_upper, up_string)
    lower_string = "resid {} {}".format(sel_lower, low_string)


    # run MembraneCurvature on both leaflets
    curvature_upper_leaflet = MembraneCurvature(universe,              # universe
                                                select = upper_string, # selection of reference
                                                n_x_bins = bins,       # bins in the x_dim
                                                n_y_bins = bins,       # bins in the y_dim
                                                wrap = True).run()     # wrap coordinated to 
                                                                       # keep atoms in the 
                                                                       # main unit cell
    
    curvature_lower_leaflet = MembraneCurvature(universe,
                                                select = lower_string,
                                                n_x_bins = bins,
                                                n_y_bins = bins,
                                                wrap = True).run()
    
    
    # print basic information on universe size
    print("Universe info:")
    print("\nBox dimensions[x,y,z]: {}." \
          "".format(universe.dimensions[:3]))

    print("\n{} residues and {} atoms." \
         "".format(universe.residues.n_residues, universe.residues.n_atoms))

    print("\nThe trajectory includes {} frames."\
          "".format(universe.trajectory.n_frames))
    
    print(" ")
    print("Number of bins in x and y dimensions of grid:")
    print(bins)
    print(" ")

    # progress bar
    pbar = ProgressBar().start()
    total_step = 2
    step = 1

    # extract data 
    [a, b, c, d, e, f] = curvature_data_extraction(curvature_upper_leaflet)
    [g, h, i, j, k, l] = curvature_data_extraction(curvature_lower_leaflet)
   
    # define 2D and 3D data
    data2D = [d, e, f] + [j, k, l]
    
    names2D = ['up_Avg_surface',
               'up_Avg_mean_curvature',
               'up_Avg_gaussian_curvature',
               'low_Avg_surface',
               'low_Avg_mean_curvature',
               'low_Avg_gaussian_curvature']

    
    data3D = [a, b, c] + [g, h, i]
    
    names3D = ['up_AF_surface',
               'up_AF_mean_curvature',
               'up_AF_gaussian_curvature',
               'low_AF_surface',
               'low_AF_mean_curvature',
               'low_AF_gaussian_curvature']
    
    # combine data and data lables 
    all_data2D = list(zip(names2D, data2D))
    all_data3D = list(zip(names3D, data3D))

    # save to output folder
    for tup2 in all_data2D:
        np.savetxt(out_folder + '/' + tup2[0] + '.dat',
                   tup2[1],
                   delimiter = '\t',
                   fmt = '%1.4f')

    # only multiframe data is 3D and needs to be reshaped
    for tup3 in all_data3D:
        np.savetxt(out_folder + '/' + tup3[0] + '.dat',
                   tup3[1].reshape(tup3[1].shape[0], -1),
                   delimiter = '\t',
                   fmt = '%1.4f')


    pbar.finish()

#------------------------------------------------------------

def main():

    description= 'LipidDyn pipeline for calculating different parameters' \
                 'of a Molecular Dynamics simulation of lipid membrane'

    parser = argparse.ArgumentParser(description=description)

    parser.add_argument('-s',
                        '--topology',
                        dest='topology',
                        type=str,
                        required=True,
                        help='Molecular topology file [.gro]',
                        )

    parser.add_argument('-f',
                        '--trajectory',
                        dest='trajectory',
                        type=str,
                        required=True,
                        help='Trajectory files [<.xtc/.trr/>] ',
                        )


    parser.add_argument('-g',
                        '--config-file',
                        dest='configuration',
                        type=str,
                        required=True,
                        help='Configuration file for headgroups selection')

    
    parser.add_argument('-o',
                        '--output-dir',
                        dest='output_dir',
                        type=str,
                        default='./',
                        help="Directory where the output of the analyses \
                              will be written")

    parser.add_argument('-a',
                        '--all',
                        dest='all_modules',
                        action='store_true',
                        help='Execute all the analysis of the pipeline'
                        )

    parser.add_argument('-fatslim',
                        '--fatslim',
                        action='store_true',
                        dest='mod_fat',
                        help='Execute only the fatslim analysis of the pipeline'
                        )

    parser.add_argument('-2d',
                        '--2d_maps',
                        action='store_true',
                        dest='mod_maps',
                        help='Execute only the density maps module of the \
                              pipeline'
                        )

    parser.add_argument('-mov',
                        '--movements',
                        action='store_true',
                        dest='mod_mov',
                        help='Execute only the movement module of the \
                              pipeline'
                       )

    parser.add_argument('-op',
                        '--order_parameter',
                        action='store_true',
                        dest='mod_ord',
                        help='Execute only the order parameter module of \
                              the pipeline'
                        )

    parser.add_argument('-mc',
                        '--membrane_curvature',
                        action='store_true',
                        dest='mod_curv',
                        help='Execute only the membrane curvature module of \
                              the pipeline'
                        )


    parser.add_argument('-enr',
                        '--enrichment',
                        action='store_true',
                        dest='enrichment',
                        help='Execute only the enrichment analysis module \
                              of the pipeline'
                       )

    parser.add_argument('-p',
                        '--protein',
                        action='store_true',
                        dest='prot',
                        help='Specify if a protein is embedded \
                              in the membrane'
                       )

    parser.add_argument('-n',
                        '--ncores',
                        nargs ='?',
                        default = 2,
                        type=int,
                        dest='cores',
                        help='Specify on how many cores to use for \
                              parallelization'
                       )   

    parser.add_argument('-a_cutoff',
                        '--apl-cutoff',
                        default= 3.0,
                        type=float,
                        dest='apl_cutoff',
                        help='Cutoff distance (in nm) used to approximate \
                              planar region (default: 3.0)'
                        )

    parser.add_argument('-t_cutoff',
                        '--thickness-cutoff',
                        default= 6.0,
                        type=float,
                        dest='tck_cutoff',
                        help='Cutoff distance (in nm) used to identify \
                              inter-leaflet neighbors (default: 6.0)'
                        )

    parser.add_argument('-r',
                        '--raw',
                        action='store_true',
                        dest='raw',
                        help='Get the raw value of thickness and apl for \
                              each frame'
                       )

    parser.add_argument('-spe',
                        '--species',
                        action='store_true',
                        dest='species',
                        help='Get a lipid species specific xvg file for the fatslim analysis'
                       )

    parser.add_argument('-c',
                        '--clean',
                        action='store_true',
                        dest='clean',
                        help='Clean all the temporary files '
                        )

    args = parser.parse_args()

    

    # Define Flags
    traj = os.path.abspath(args.trajectory)
    topol = os.path.abspath(args.topology)
    hg_sel = os.path.abspath(args.configuration)
    out_dir = args.output_dir
    ncore = args.cores
    cleaning = args.clean
    apl_cutoff = args.apl_cutoff
    tck_cutoff = args.tck_cutoff
    raw = args.raw
    species = args.species
    all_modules = args.all_modules
    
     # Setup log module
    logging.basicConfig(filename=os.path.join(out_dir, 'LipidDynRun.log'),
                        level=logging.INFO,
                        format='%(asctime)s:%(levelname)s:%(message)s')
    

    starting_directory = os.getcwd()
 

    # Check if the output directory exists 
    if not os.path.exists(out_dir):
        logging.error("The output directory doesn't exist")
        exit(1)
    
    # Check if the selected filename is actually a directory
    if not os.path.isdir(out_dir):
        logging.error(f"{out_dir} is not a directory")
        exit(1)

    # setup of the MDA universe
    u = mda.Universe(topol,traj,in_memory=True)

    # load config file for atom selections   
    try:
        with open(hg_sel) as config:
            parsed_yaml = yaml.load(config, Loader=yaml.FullLoader)
        
            if not isinstance(parsed_yaml, dict):  
                logging.error("Couldn't parse the configuration file \
                               correctly; check its file format")
                exit(1)
    
    except IOError:
        logging.error("Configuration file doesn't exists \
                       or is not accessible")
        exit(1)
    
    except:
        logging.error("Loading the configuration file failed;\
                       please check its format")
        exit(1)
    
    try:
        # define dictionary selections                
        dict_selection=parsed_yaml["lipids"]    
        dict_prot=(parsed_yaml["protein"])
        
    except KeyError:        
            logging.error("protein and lipids sections not found \
                           in configuration file")
            exit(1)
    
    # Means a protein is embedded in the bilayer
    if args.prot :
        # call utils module for heagroup selection
        g = select_lipid_headgroups(u, dict_selection)
        p = u.select_atoms(dict_prot)

        with mda.selections.gromacs.SelectionWriter(os.path.join(out_dir,
                                        'index_headgroups.ndx'),
                                         mode='a') as ndx:
            ndx.write(g, name="headgroups", frame=0)
            ndx.write(p, name="protein", frame=0)

    else:
        # call utils module for the heagroup selection
        g = select_lipid_headgroups(u, dict_selection)
        with mda.selections.gromacs.SelectionWriter(os.path.join(out_dir,
                                        'index_headgroups.ndx'),
                                         mode='w') as ndx:
            ndx.write(g, name="headgroups", frame=0)

    lipid_resnames = np.unique(g.residues.resnames)   
    # Find leaflets and store them in a dictionary
    L =  LeafletFinder(u,g)

    upper_leaflet = L.groups(0)
    lower_leaflet = L.groups(1)

    leaflets = {"upper_leaflet":upper_leaflet,
                "lower_leaflet":lower_leaflet}
    
      
    # index file of headgroups
    index_headgroups = os.path.join(out_dir,
                       'index_headgroups.ndx')


    # Create an index file in which the different layers of the membrane
    # are listed

    with mda.selections.gromacs.SelectionWriter(os.path.join(out_dir, 
                                                'true_bilayer.ndx'),
                                                 mode='w') as ndx:
            ndx.write(upper_leaflet, name="upper_leaflet")
            ndx.write(lower_leaflet, name="lower_leaflet")
    
    # Create a dataframe that correlates resid with Lipid Species
    RS_convert = pd.DataFrame({'resid': list(g.resids), 
                               'Species': list(g.resnames)})
    
    # The user selected the -all flag for all the analysis
    if all_modules:
        args.mod_fat = True
        args.mod_maps = True
        args.enrichment = True
        args.mod_mov = True
        args.mod_ord = True
        args.mod_curv = True

    logging.info("Starting now with the calculation, please stand by")
    logging.info(u"\u2622")

    if args.mod_fat:
        logging.info("Analysis: Area per lipid & Thickness calculation")
        module_fatslim(traj,
                       topol,
                       index_headgroups,
                       out_dir,
                       apl_cutoff,
                       tck_cutoff,
                       raw,
                       species,
                       ncore,
                       RS_convert)
        logging.info("--------------------------------------")

    if args.mod_maps:
        logging.info("Analysis: Density maps")
        module_densmap(u,
                       leaflets,
                       ncore,
                       out_dir)
        logging.info("--------------------------------------")

    if args.mod_curv:
        logging.info("Analysis: Membrane Curvature")
        module_curvature(u,
                         parsed_yaml,
                         out_dir)

        logging.info("--------------------------------------")

    if args.enrichment:
        if args.prot:
            # add enrichment analysis with a protein
            # do it if there is also the flag for the
            # prot
            logging.info("Analysis: Enrichment Analysis")
            module_enrichment(u,
                              leaflets,
                              dict_selection,
                              ncore,
                              out_dir)
            logging.info("--------------------------------------")

        else:
            logging.error("Enrichment can only be performed on simulations with proteins embedded in the membrane")

    if args.mod_mov:
        logging.info("Analysis: Diffusion movements")
        module_movements(u,
                         leaflets,
                         out_dir)
        logging.info("--------------------------------------")

    if args.mod_ord:
        logging.info("Analysis: Order Parameter")
        module_order_parameter(u,
                               lipid_resnames,
                               traj,
                               topol,
                               parsed_yaml,
                               out_dir)
        logging.info("--------------------------------------")

    if args.clean :
        os.remove(os.path.join(out_dir, 'index_headgroups.ndx'))
        os.remove(os.path.join(out_dir, 'true_bilayer.ndx'))

if __name__ == "__main__":
    main()
